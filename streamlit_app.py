import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import RandomizedSearchCV, train_test_split, TimeSeriesSplit
import plotly.express as px
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def load_data(file):
    message_placeholder = st.empty()
    if file is None:
        st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸” à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV")
        return None

    try:
        df = pd.read_csv(file)
        if df.empty:
            st.error("à¹„à¸Ÿà¸¥à¹Œ CSV à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸² à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
            return None
        message_placeholder.success("à¹„à¸Ÿà¸¥à¹Œà¸–à¸¹à¸à¹‚à¸«à¸¥à¸”à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§")
        return df
    except pd.errors.EmptyDataError:
        st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œà¹„à¸”à¹‰ à¹„à¸Ÿà¸¥à¹Œà¸­à¸²à¸ˆà¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸²à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹„à¸Ÿà¸¥à¹Œ CSV à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        return None
    except pd.errors.ParserError:
        st.error("à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹à¸¢à¸à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹„à¸Ÿà¸¥à¹Œ CSV à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œ")
        return None
    except Exception as e:
        st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ: {e}")
        return None
    finally:
        message_placeholder.empty()

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def clean_data(df):
    data_clean = df.copy()
    data_clean['datetime'] = pd.to_datetime(data_clean['datetime'], errors='coerce')
    data_clean = data_clean.dropna(subset=['datetime'])
    data_clean = data_clean[(data_clean['wl_up'] >= 100) & (data_clean['wl_up'] <= 450)]
    data_clean = data_clean[(data_clean['wl_up'] != 0) & (~data_clean['wl_up'].isna())]
    return data_clean

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¹€à¸§à¸¥à¸²
def create_time_features(data_clean):
    if not pd.api.types.is_datetime64_any_dtype(data_clean['datetime']):
        data_clean['datetime'] = pd.to_datetime(data_clean['datetime'], errors='coerce')

    data_clean['year'] = data_clean['datetime'].dt.year
    data_clean['month'] = data_clean['datetime'].dt.month
    data_clean['day'] = data_clean['datetime'].dt.day
    data_clean['hour'] = data_clean['datetime'].dt.hour
    data_clean['minute'] = data_clean['datetime'].dt.minute
    data_clean['day_of_week'] = data_clean['datetime'].dt.dayofweek
    data_clean['day_of_year'] = data_clean['datetime'].dt.dayofyear
    data_clean['week_of_year'] = data_clean['datetime'].dt.isocalendar().week
    data_clean['days_in_month'] = data_clean['datetime'].dt.days_in_month

    return data_clean

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸•à¸£à¸µà¸¢à¸¡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ
def prepare_features(data_clean):
    feature_cols = [
        'year', 'month', 'day', 'hour', 'minute',
        'day_of_week', 'day_of_year', 'week_of_year',
        'days_in_month', 'wl_up_prev'
    ]
    X = data_clean[feature_cols]
    y = data_clean['wl_up']
    return X, y

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸¶à¸à¹à¸¥à¸°à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¹‚à¸¡à¹€à¸”à¸¥
def train_and_evaluate_model(X, y, model_type='random_forest'):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if model_type == 'random_forest':
        model = train_random_forest(X_train, y_train)
    elif model_type == 'linear_regression':
        model = train_linear_regression_model(X_train, y_train)
    else:
        st.error("à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        return None

    if model is None:
        st.error("à¸à¸²à¸£à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§")
        return None
    return model

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸¶à¸ Random Forest
def train_random_forest(X_train, y_train):
    param_distributions = {
        'n_estimators': [100, 200, 500],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2],
        'max_features': ['auto', 'sqrt'],
        'bootstrap': [True, False]
    }

    rf = RandomForestRegressor(random_state=42)

    tscv = TimeSeriesSplit(n_splits=5)
    random_search = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_distributions,
        n_iter=20,
        cv=tscv,
        n_jobs=-1,
        verbose=2,
        random_state=42,
        scoring='neg_mean_absolute_error'
    )
    random_search.fit(X_train, y_train)

    return random_search.best_estimator_

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸¶à¸ Linear Regression
def train_linear_regression_model(X_train, y_train):
    model = LinearRegression()
    model.fit(X_train, y_train)
    return model

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸£à¸šà¸–à¹‰à¸§à¸™
def generate_missing_dates(data):
    full_date_range = pd.date_range(start=data['datetime'].min(), end=data['datetime'].max(), freq='15T')
    all_dates = pd.DataFrame(full_date_range, columns=['datetime'])
    data_with_all_dates = pd.merge(all_dates, data, on='datetime', how='left')
    return data_with_all_dates

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸•à¸´à¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'code'
def fill_code_column(data):
    if 'code' in data.columns:
        data['code'] = data['code'].fillna(method='ffill').fillna(method='bfill')
    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›
def handle_missing_values_by_week(data_clean, start_date, end_date, model_type='random_forest'):
    feature_cols = ['year', 'month', 'day', 'hour', 'minute',
                    'day_of_week', 'day_of_year', 'week_of_year', 'days_in_month', 'wl_up_prev']

    data = data_clean.copy()

    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)

    data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]

    data_with_all_dates = generate_missing_dates(data)
    data_with_all_dates.index = pd.to_datetime(data_with_all_dates['datetime'])
    data_missing = data_with_all_dates[data_with_all_dates['wl_up'].isnull()]
    data_not_missing = data_with_all_dates.dropna(subset=['wl_up'])

    if 'wl_up_prev' in data_with_all_dates.columns:
        data_with_all_dates['wl_up_prev'] = data_with_all_dates['wl_up_prev'].interpolate(method='linear')
    else:
        data_with_all_dates['wl_up_prev'] = data_with_all_dates['wl_up'].shift(1).interpolate(method='linear')

    if len(data_missing) == 0:
        st.write("No missing values to predict.")
        return data_with_all_dates

    X_train, y_train = prepare_features(data_not_missing)
    model = train_and_evaluate_model(X_train, y_train, model_type=model_type)

    if model is None:
        st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸”à¹‰ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        return data_with_all_dates

    for idx, row in data_missing.iterrows():
        X_missing = row[feature_cols].values.reshape(1, -1)
        try:
            predicted_value = model.predict(X_missing)[0]
            data_with_all_dates.loc[idx, 'wl_forecast'] = predicted_value
            data_with_all_dates.loc[idx, 'timestamp'] = pd.Timestamp.now()
        except Exception as e:
            st.warning(f"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¹ˆà¸²à¹ƒà¸™à¹à¸–à¸§ {idx} à¹„à¸”à¹‰: {e}")
            continue

    data_with_all_dates['wl_up2'] = data_with_all_dates['wl_up'].combine_first(data_with_all_dates['wl_forecast'])

    data_with_all_dates.reset_index(drop=True, inplace=True)
    return data_with_all_dates

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆ
def delete_data_by_date_range(data, delete_start_date, delete_end_date):
    delete_start_date = pd.to_datetime(delete_start_date)
    delete_end_date = pd.to_datetime(delete_end_date)

    data_to_delete = data[(data['datetime'] >= delete_start_date) & (data['datetime'] <= delete_end_date)]

    if len(data_to_delete) == 0:
        st.warning(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ {delete_start_date} à¹à¸¥à¸° {delete_end_date}.")
    elif len(data_to_delete) > (0.3 * len(data)):
        st.warning("à¸„à¸³à¹€à¸•à¸·à¸­à¸™: à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›à¸—à¸µà¹ˆà¸ˆà¸°à¸¥à¸š à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸¥à¸šà¸–à¸¹à¸à¸¢à¸à¹€à¸¥à¸´à¸")
    else:
        data.loc[data_to_delete.index, 'wl_up'] = np.nan

    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
def calculate_accuracy_metrics(original, filled):
    merged_data = pd.merge(original[['datetime', 'wl_up']], filled[['datetime', 'wl_up2']], on='datetime')

    merged_data = merged_data.dropna(subset=['wl_up', 'wl_up2'])

    comparison_data = merged_data[merged_data['wl_up2'] != merged_data['wl_up']]

    if comparison_data.empty:
        st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³", divider='gray')
        st.info("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸«à¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š")
    else:
        mse = mean_squared_error(comparison_data['wl_up'], comparison_data['wl_up2'])
        mae = mean_absolute_error(comparison_data['wl_up'], comparison_data['wl_up2'])
        r2 = r2_score(comparison_data['wl_up'], comparison_data['wl_up2'])

        st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³", divider='gray')

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(label="Mean Squared Error (MSE)", value=f"{mse:.4f}")
        with col2:
            st.metric(label="Mean Absolute Error (MAE)", value=f"{mae:.4f}")
        with col3:
            st.metric(label="R-squared (RÂ²)", value=f"{r2:.4f}")

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
def plot_results(data_before, data_filled, data_deleted):
    data_before_filled = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_before['datetime'],
        'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡': data_before['wl_up']
    })

    data_after_filled = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_filled['datetime'],
        'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²': data_filled['wl_up2']
    })

    data_after_deleted = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_deleted['datetime'],
        'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š': data_deleted['wl_up']
    })

    combined_data = pd.merge(data_before_filled, data_after_filled, on='à¸§à¸±à¸™à¸—à¸µà¹ˆ', how='outer')
    combined_data = pd.merge(combined_data, data_after_deleted, on='à¸§à¸±à¸™à¸—à¸µà¹ˆ', how='outer')

    fig = px.line(combined_data, x='à¸§à¸±à¸™à¸—à¸µà¹ˆ', y=['à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡', 'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²', 'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š'],
                  labels={'value': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)', 'variable': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥'},
                  title="à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›")

    fig.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)")

    st.plotly_chart(fig, use_container_width=True)

    st.header("à¸•à¸²à¸£à¸²à¸‡à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²", divider='gray')
    data_filled_selected = data_filled[['code', 'datetime', 'wl_up', 'wl_forecast', 'timestamp']]
    st.dataframe(data_filled_selected, use_container_width=True)

    merged_data = pd.merge(data_before[['datetime', 'wl_up']], data_filled[['datetime', 'wl_up2']], on='datetime')
    merged_data = merged_data.dropna(subset=['wl_up', 'wl_up2'])
    comparison_data = merged_data[merged_data['wl_up2'] != merged_data['wl_up']]

    if comparison_data.empty:
        st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³", divider='gray')
        st.info("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸«à¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š")
    else:
        calculate_accuracy_metrics(data_before, data_filled)

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def plot_data_preview(data1, data2, total_time_lag):
    data_pre1 = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data1['datetime'],
        'à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢': data1['wl_up']
    })

    if data2 is not None:
        data_pre2 = pd.DataFrame({
            'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data2['datetime'] + total_time_lag,
            'à¸ªà¸–à¸²à¸™à¸µà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²': data2['wl_up']
        })
        combined_data_pre = pd.merge(data_pre1, data_pre2, on='à¸§à¸±à¸™à¸—à¸µà¹ˆ', how='outer')

        red_colors = ['#FF9999', '#FF4C4C']

        fig = px.line(
            combined_data_pre,
            x='à¸§à¸±à¸™à¸—à¸µà¹ˆ',
            y=['à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢', 'à¸ªà¸–à¸²à¸™à¸µà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²'],
            labels={'value': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)', 'variable': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥'},
            title='à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ',
            color_discrete_sequence=red_colors
        )

        fig.update_layout(
            xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ",
            yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)",
            legend_title="à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥",
            hovermode="x unified"
        )

        fig.update_xaxes(rangeslider_visible=True)

        st.plotly_chart(fig, use_container_width=True)
    else:
        red_colors_single = ['#FF4C4C']

        fig = px.line(
            data_pre1,
            x='à¸§à¸±à¸™à¸—à¸µà¹ˆ',
            y='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢',
            labels={'à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'},
            title='à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ',
            color_discrete_sequence=red_colors_single
        )

        fig.update_layout(
            xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ",
            yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)",
            hovermode="x unified"
        )

        fig.update_xaxes(rangeslider_visible=True)

        st.plotly_chart(fig, use_container_width=True)

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸–à¸²à¸™à¸µà¸ªà¸­à¸‡
def merge_data(df1, df2=None):
    if df2 is not None:
        merged_df = pd.merge(df1, df2[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_prev'))
    else:
        df1['wl_up_prev'] = df1['wl_up'].shift(1)
        merged_df = df1.copy()
    return merged_df

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ Linear Regression à¸ˆà¸²à¸à¹‚à¸„à¹‰à¸”à¸—à¸µà¹ˆ 2 à¹à¸¥à¸° 3
def forecast_with_linear_regression(target_data, upstream_data, forecast_start_date, delay_hours=0):
    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ upstream_data
    upstream_data = upstream_data.copy()
    if delay_hours > 0:
        upstream_data['datetime'] = upstream_data.index + pd.Timedelta(hours=delay_hours)
        upstream_data.set_index('datetime', inplace=True)

    # à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 672 à¹à¸–à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸ˆà¸²à¸ upstream_data à¹ƒà¸™à¸à¸²à¸£à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
    training_data = upstream_data.iloc[-672:].copy()

    # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag
    lags = [1, 4, 96, 192]  # lag 15 à¸™à¸²à¸—à¸µ, 1 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡, 1 à¸§à¸±à¸™, 2 à¸§à¸±à¸™
    for lag in lags:
        training_data[f'lag_{lag}'] = training_data['wl_up'].shift(lag)

    # à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN à¹ƒà¸™à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag
    training_data.dropna(inplace=True)

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¸¢à¸‡à¸à¸­à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag
    if training_data.empty:
        st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸à¸µà¸¢à¸‡à¸à¸­à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag")
        return pd.DataFrame()

    # à¸à¸³à¸«à¸™à¸”à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¹à¸¥à¸°à¸•à¸±à¸§à¹à¸›à¸£à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
    feature_cols = [f'lag_{lag}' for lag in lags]
    X_train = training_data[feature_cols]
    y_train = training_data['wl_up']

    # à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥ Linear Regression
    model = LinearRegression()
    model.fit(X_train, y_train)

    # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    forecast_periods = 96  # à¸à¸¢à¸²à¸à¸£à¸“à¹Œ 1 à¸§à¸±à¸™ (96 à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸² 15 à¸™à¸²à¸—à¸µ)
    forecast_index = pd.date_range(start=forecast_start_date, periods=forecast_periods, freq='15T')
    forecasted_data = pd.DataFrame(index=forecast_index)
    forecasted_data['wl_up'] = np.nan

    # à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    for idx in forecasted_data.index:
        lag_features = {}
        for lag in lags:
            lag_time = idx - pd.Timedelta(minutes=15 * lag)
            if lag_time in target_data.index:
                lag_value = target_data.at[lag_time, 'wl_up']
            else:
                lag_value = np.nan
            lag_features[f'lag_{lag}'] = lag_value

        # à¸–à¹‰à¸²à¸¡à¸µà¸„à¹ˆà¸² lag à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸› à¹ƒà¸«à¹‰à¸‚à¹‰à¸²à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        if np.any(pd.isnull(list(lag_features.values()))):
            continue

        # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ªà¸³à¸«à¸£à¸±à¸šà¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¸—à¸µà¹ˆà¸ˆà¸°à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        X_pred = pd.DataFrame([lag_features])

        # à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¹ˆà¸²
        forecast_value = model.predict(X_pred)[0]
        forecasted_data.at[idx, 'wl_up'] = forecast_value

    # à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    forecasted_data.dropna(inplace=True)

    return forecasted_data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
def plot_data_combined(data, forecasted=None, label='à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³'):
    fig = px.line(data, x=data.index, y='wl_up', title=f'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µ {label}', labels={'x': 'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'wl_up': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'})
    fig.update_traces(connectgaps=False)
    if forecasted is not None and not forecasted.empty:
        fig.add_scatter(x=forecasted.index, y=forecasted['wl_up'], mode='lines', name='à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ', line=dict(color='red'))
    fig.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)")
    return fig

# Streamlit UI
st.set_page_config(
    page_title="à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³",
    page_icon="ğŸŒŠ",
    layout="wide"
)

st.markdown("""
# à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³

à¹à¸­à¸› Streamlit à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ **Random Forest** à¸«à¸£à¸·à¸­ **Linear Regression** à¹€à¸à¸·à¹ˆà¸­à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹à¸¥à¸°à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥à¸œà¹ˆà¸²à¸™à¸à¸£à¸²à¸Ÿà¹à¸¥à¸°à¸à¸²à¸£à¸§à¸±à¸”à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¸·à¸­à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ, 
à¸à¸³à¸«à¸™à¸”à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰
""")
st.markdown("---")

# Sidebar: Upload files and choose date ranges
with st.sidebar:

    st.sidebar.title("à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ")
    with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥", expanded=True):
        model_choice = st.sidebar.radio("", ("Random Forest", "Linear Regression"))

    st.sidebar.title("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
    if model_choice == "Random Forest":
        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Random Forest", expanded=False):
            use_second_file = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡", value=False)
            
            if use_second_file:
                uploaded_file2 = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ (à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²)", type="csv", key="uploader2_rf")
                uploaded_file = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢", type="csv", key="uploader1_rf")
            else:
                uploaded_file2 = None
                uploaded_file = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢", type="csv", key="uploader1_rf")

            if use_second_file:
                time_lag_days = st.number_input("à¸£à¸°à¸šà¸¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ (à¸§à¸±à¸™)", value=0, min_value=0)
                total_time_lag = pd.Timedelta(days=time_lag_days)
            else:
                total_time_lag = pd.Timedelta(days=0)

        with st.sidebar.expander("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", expanded=False):
            start_date = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™", value=pd.to_datetime("2024-05-01"))
            end_date = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”", value=pd.to_datetime("2024-05-31"))
            
            delete_data_option = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=False)

            if delete_data_option:
                st.header("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
                delete_start_date = st.date_input("à¸à¸³à¸«à¸™à¸”à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=start_date, key='delete_start_rf')
                delete_start_time = st.time_input("à¹€à¸§à¸¥à¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™", value=pd.Timestamp("00:00:00").time(), key='delete_start_time_rf')
                delete_end_date = st.date_input("à¸à¸³à¸«à¸™à¸”à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=end_date, key='delete_end_rf')
                delete_end_time = st.time_input("à¹€à¸§à¸¥à¸²à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”", value=pd.Timestamp("23:45:00").time(), key='delete_end_time_rf')

        process_button = st.button("à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥", type="primary")

    elif model_choice == "Linear Regression":
        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Linear Regression", expanded=False):
            uploaded_up_file = st.file_uploader("à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ CSV à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µà¸‚à¹‰à¸²à¸‡à¸šà¸™ (up)", type="csv")
            uploaded_target_file = st.file_uploader("à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ CSV à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢", type="csv")
            uploaded_fill_file = st.file_uploader("à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ CSV à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥", type="csv")

        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", expanded=False):
            forecast_start_date = st.date_input("à¹€à¸¥à¸·à¸­à¸à¸§à¸±à¸™à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", value=pd.to_datetime("2024-06-01"))
            forecast_start_time = st.time_input("à¹€à¸¥à¸·à¸­à¸à¹€à¸§à¸¥à¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", value=pd.Timestamp("00:00:00").time())
            forecast_end_date = st.date_input("à¹€à¸¥à¸·à¸­à¸à¸§à¸±à¸™à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", value=pd.to_datetime("2024-06-02"))
            forecast_end_time = st.time_input("à¹€à¸¥à¸·à¸­à¸à¹€à¸§à¸¥à¸²à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", value=pd.Timestamp("23:45:00").time())
            delay_hours = st.number_input("à¸£à¸°à¸šà¸¸à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡à¸«à¸™à¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸–à¸²à¸™à¸µà¸‚à¹‰à¸²à¸‡à¸šà¸™ (up)", value=0, min_value=0)

            use_second_file_lr = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression", value=False)

            if use_second_file_lr:
                uploaded_file2_lr = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ (à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²)", type="csv", key="uploader2_lr")
            else:
                uploaded_file2_lr = None

        process_button2 = st.button("à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥", type="primary")

# Main content: Display results after file uploads and date selection
if model_choice == "Random Forest":
    if uploaded_file:
        df = load_data(uploaded_file)
        
        if df is not None:
            df_pre = clean_data(df)
            df_pre = generate_missing_dates(df_pre)

            if use_second_file:
                if uploaded_file2 is not None:
                    df2 = load_data(uploaded_file2)
                    if df2 is not None:
                        df2_pre = clean_data(df2)
                        df2_pre = generate_missing_dates(df2_pre)
                    else:
                        df2_pre = None
                else:
                    st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸­à¸‡ (à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²)")
                    df2_pre = None
            else:
                df2_pre = None

            plot_data_preview(df_pre, df2_pre, total_time_lag)

            if process_button:
                processing_placeholder = st.empty()
                processing_placeholder.text("à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥...")

                df['datetime'] = pd.to_datetime(df['datetime']).dt.tz_localize(None)

                end_date_dt = pd.to_datetime(end_date) + pd.DateOffset(days=1)

                df_filtered = df[(df['datetime'] >= pd.to_datetime(start_date)) & (df['datetime'] <= pd.to_datetime(end_date_dt))]

                if use_second_file and uploaded_file2 and df2 is not None:
                    df2['datetime'] = pd.to_datetime(df2['datetime']).dt.tz_localize(None)
                    df2_filtered = df2[(df2['datetime'] >= pd.to_datetime(start_date)) & (df2['datetime'] <= pd.to_datetime(end_date_dt))]
                    df2_filtered['datetime'] = df2_filtered['datetime'] + total_time_lag
                    df2_clean = clean_data(df2_filtered)
                else:
                    df2_clean = None

                df_clean = clean_data(df_filtered)

                df_merged = merge_data(df_clean, df2_clean)

                if delete_data_option:
                    delete_start_datetime = pd.to_datetime(f"{delete_start_date} {delete_start_time}")
                    delete_end_datetime = pd.to_datetime(f"{delete_end_date} {delete_end_time}")
                    df_deleted = delete_data_by_date_range(df_merged, delete_start_datetime, delete_end_datetime)
                else:
                    df_deleted = df_merged.copy()

                df_clean = generate_missing_dates(df_deleted)
                df_clean = fill_code_column(df_clean)
                df_clean = create_time_features(df_clean)

                if 'wl_up_prev' not in df_clean.columns:
                    df_clean['wl_up_prev'] = df_clean['wl_up'].shift(1)
                df_clean['wl_up_prev'] = df_clean['wl_up_prev'].interpolate(method='linear')

                df_before_deletion = df_filtered.copy()

                df_handled = handle_missing_values_by_week(df_clean, start_date, end_date, model_type='random_forest')

                processing_placeholder.empty()

                plot_results(df_before_deletion, df_handled, df_deleted)
    else:
        st.info("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥")

elif model_choice == "Linear Regression":
    if uploaded_up_file is not None and uploaded_target_file is not None and uploaded_fill_file is not None:
        # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        fill_data = load_data(uploaded_fill_file)
        if fill_data is not None:
            fill_data = clean_data(fill_data)
            fill_data = generate_missing_dates(fill_data)
            fill_data = fill_data.set_index('datetime')
        else:
            fill_data = None

        # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ upstream à¹à¸¥à¸° target
        up_data = load_data(uploaded_up_file)
        target_data = load_data(uploaded_target_file)

        if up_data is not None and target_data is not None:
            up_data = clean_data(up_data)
            up_data = generate_missing_dates(up_data)
            up_data = up_data.set_index('datetime')

            target_data = clean_data(target_data)
            target_data = generate_missing_dates(target_data)
            target_data = target_data.set_index('datetime')

            st.subheader('à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³')
            st.plotly_chart(plot_data_combined(target_data, label='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢'))
            st.plotly_chart(plot_data_combined(up_data, label='à¸ªà¸–à¸²à¸™à¸µà¸‚à¹‰à¸²à¸‡à¸šà¸™ (up)'))

            if use_second_file_lr:
                if uploaded_file2_lr is not None:
                    df2_lr = load_data(uploaded_file2_lr)
                    if df2_lr is not None:
                        df2_lr = clean_data(df2_lr)
                        df2_lr = generate_missing_dates(df2_lr)
                        df2_lr = df2_lr.set_index('datetime')
                    else:
                        df2_lr = None
                else:
                    st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸­à¸‡ (à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²) à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression")
                    df2_lr = None
            else:
                df2_lr = None

            if process_button2:
                with st.spinner("à¸à¸³à¸¥à¸±à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ..."):
                    start_datetime = pd.Timestamp.combine(forecast_start_date, forecast_start_time)
                    end_datetime = pd.Timestamp.combine(forecast_end_date, forecast_end_time)

                    if start_datetime > end_datetime:
                        st.error("à¸§à¸±à¸™à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸•à¹‰à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™à¸§à¸±à¸™à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”")
                    else:
                        selected_data = target_data[(target_data.index >= start_datetime) & (target_data.index <= end_datetime)].copy()

                        if selected_data.empty:
                            st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸§à¸±à¸™à¸—à¸µà¹ˆà¹ƒà¸«à¸¡à¹ˆ")
                        else:
                            forecast_start_date_actual = selected_data.index.max() + pd.Timedelta(minutes=15)

                            # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›à¸ˆà¸²à¸ fill_data à¸à¹ˆà¸­à¸™à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
                            if fill_data is not None:
                                target_data = target_data.combine_first(fill_data['wl_up'])
                                target_data = target_data.fillna(method='ffill').fillna(method='bfill')

                            # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸–à¸²à¸™à¸µà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸–à¹‰à¸²à¸¡à¸µ
                            if use_second_file_lr and df2_lr is not None:
                                # à¸­à¸²à¸ˆà¸•à¹‰à¸­à¸‡à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ df2_lr à¹€à¸‚à¹‰à¸²à¸à¸±à¸š target_data à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£
                                target_data = merge_data(target_data.reset_index(), df2_lr.reset_index())
                                target_data = target_data.set_index('datetime')
                            
                            # à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ Linear Regression
                            forecasted_data = forecast_with_linear_regression(
                                target_data, up_data, forecast_start_date_actual, delay_hours
                            )

                            if not forecasted_data.empty:
                                st.subheader('à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ')
                                st.plotly_chart(plot_data_combined(selected_data, forecasted_data, label='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢'))

                                common_indices = forecasted_data.index.intersection(target_data.index)
                                if not common_indices.empty:
                                    actual_data = target_data.loc[common_indices]
                                    y_true = actual_data['wl_up']
                                    y_pred = forecasted_data['wl_up'].loc[common_indices]

                                    min_length = min(len(y_true), len(y_pred))
                                    y_true = y_true[:min_length]
                                    y_pred = y_pred[:min_length]

                                    mae = mean_absolute_error(y_true, y_pred)
                                    rmse = mean_squared_error(y_true, y_pred, squared=False)

                                    st.subheader('à¸•à¸²à¸£à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š')
                                    comparison_table = pd.DataFrame({
                                        'datetime': forecasted_data.index[:min_length],
                                        'à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡ (à¸–à¹‰à¸²à¸¡à¸µ)': y_true.values,
                                        'à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ': y_pred.values
                                    })
                                    st.dataframe(comparison_table)

                                    st.write(f"Mean Absolute Error (MAE): {mae:.2f}")
                                    st.write(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
                                else:
                                    st.info("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸² MAE à¹à¸¥à¸° RMSE à¹„à¸”à¹‰")
                            else:
                                st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸à¸µà¸¢à¸‡à¸à¸­")
    else:
        st.info("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡à¸ªà¸²à¸¡à¹„à¸Ÿà¸¥à¹Œ (à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢, à¸ªà¸–à¸²à¸™à¸µà¸‚à¹‰à¸²à¸‡à¸šà¸™, à¹à¸¥à¸°à¹„à¸Ÿà¸¥à¹Œà¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥) à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ")
else:
    st.info("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰")





