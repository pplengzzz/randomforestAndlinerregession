import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import RandomizedSearchCV, train_test_split, TimeSeriesSplit
import plotly.express as px
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def load_data(file):
    message_placeholder = st.empty()  # à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸§à¹ˆà¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™
    if file is None:
        st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸” à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV")
        return None
    
    try:
        df = pd.read_csv(file)
        if df.empty:
            st.error("à¹„à¸Ÿà¸¥à¹Œ CSV à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸² à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
            return None
        message_placeholder.success("à¹„à¸Ÿà¸¥à¹Œà¸–à¸¹à¸à¹‚à¸«à¸¥à¸”à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§")  # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸§à¹ˆà¸²à¸‡
        return df
    except pd.errors.EmptyDataError:
        st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œà¹„à¸”à¹‰ à¹„à¸Ÿà¸¥à¹Œà¸­à¸²à¸ˆà¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸²à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹„à¸Ÿà¸¥à¹Œ CSV à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        return None
    except pd.errors.ParserError:
        st.error("à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹à¸¢à¸à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹„à¸Ÿà¸¥à¹Œ CSV à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œ")
        return None
    except Exception as e:
        st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ: {e}")
        return None
    finally:
        message_placeholder.empty()  # à¸¥à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def clean_data(df):
    data_clean = df.copy()
    data_clean['datetime'] = pd.to_datetime(data_clean['datetime'], errors='coerce')
    data_clean = data_clean.dropna(subset=['datetime'])
    data_clean = data_clean[(data_clean['wl_up'] >= -100)]
    data_clean = data_clean[(data_clean['wl_up'] != 0) & (~data_clean['wl_up'].isna())]
    
    # à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸š spike
    data_clean.sort_values('datetime', inplace=True)  # à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸šà¸•à¸²à¸¡à¹€à¸§à¸¥à¸²
    data_clean.reset_index(drop=True, inplace=True)
    data_clean['diff'] = data_clean['wl_up'].diff().abs()
    threshold = data_clean['diff'].median() * 5  # à¹ƒà¸Šà¹‰à¸„à¹ˆà¸² median à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡ à¸„à¸¹à¸“à¸”à¹‰à¸§à¸¢ 5
    
    # à¸£à¸°à¸šà¸¸à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ spike
    data_clean['is_spike'] = data_clean['diff'] > threshold
    data_clean.loc[data_clean['is_spike'], 'wl_up'] = np.nan
    data_clean.drop(columns=['diff', 'is_spike'], inplace=True)
    data_clean['wl_up'] = data_clean['wl_up'].interpolate(method='linear')
    
    return data_clean

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¹€à¸§à¸¥à¸²
def create_time_features(data_clean):
    if not pd.api.types.is_datetime64_any_dtype(data_clean['datetime']):
        data_clean['datetime'] = pd.to_datetime(data_clean['datetime'], errors='coerce')

    data_clean['year'] = data_clean['datetime'].dt.year
    data_clean['month'] = data_clean['datetime'].dt.month
    data_clean['day'] = data_clean['datetime'].dt.day
    data_clean['hour'] = data_clean['datetime'].dt.hour
    data_clean['minute'] = data_clean['datetime'].dt.minute
    data_clean['day_of_week'] = data_clean['datetime'].dt.dayofweek
    data_clean['day_of_year'] = data_clean['datetime'].dt.dayofyear
    data_clean['week_of_year'] = data_clean['datetime'].dt.isocalendar().week
    data_clean['days_in_month'] = data_clean['datetime'].dt.days_in_month

    return data_clean

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead
def create_lag_lead_features(data, lags=[1, 4, 96, 192], leads=[1, 4, 96, 192]):
    for lag in lags:
        data[f'lag_{lag}'] = data['wl_up'].shift(lag)
    for lead in leads:
        data[f'lead_{lead}'] = data['wl_up'].shift(-lead)
    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸—à¸µà¹ˆ
def create_moving_average_features(data, window=672):
    data[f'ma_{window}'] = data['wl_up'].rolling(window=window, min_periods=1).mean()
    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸•à¸£à¸µà¸¢à¸¡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ
def prepare_features(data_clean, lags=[1, 4, 96, 192], leads=[1, 4, 96, 192], window=672):
    feature_cols = [
        'year', 'month', 'day', 'hour', 'minute',
        'day_of_week', 'day_of_year', 'week_of_year',
        'days_in_month', 'wl_up_prev'
    ]

    # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead
    data_clean = create_lag_lead_features(data_clean, lags, leads)

    # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸—à¸µà¹ˆ
    data_clean = create_moving_average_features(data_clean, window)

    # à¹€à¸à¸´à¹ˆà¸¡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead à¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™ feature_cols
    lag_cols = [f'lag_{lag}' for lag in lags]
    lead_cols = [f'lead_{lead}' for lead in leads]
    ma_col = f'ma_{window}'
    feature_cols.extend(lag_cols + lead_cols)
    feature_cols.append(ma_col)

    # à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN à¹ƒà¸™à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead
    data_clean = data_clean.dropna(subset=feature_cols)

    X = data_clean[feature_cols[9:]]
    y = data_clean['wl_up']
    return X, y

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹à¸¥à¸°à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸œà¸¥à¹‚à¸¡à¹€à¸”à¸¥
def train_and_evaluate_model(X, y, model_type='random_forest'):
    # à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™à¸Šà¸¸à¸”à¸à¸¶à¸à¹à¸¥à¸°à¸Šà¸¸à¸”à¸—à¸”à¸ªà¸­à¸š
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥
    if model_type == 'random_forest':
        model = train_random_forest(X_train, y_train)
    elif model_type == 'linear_regression':
        model = train_linear_regression_model(X_train, y_train)
    else:
        st.error("à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        return None

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if model is None:
        st.error("à¸à¸²à¸£à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§")
        return None
    return model

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸ Random Forest
def train_random_forest(X_train, y_train):
    param_distributions = {
        'n_estimators': [200, 300, 400, 500, 600],
        'max_depth': [None, 10, 20, 30, 40],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['auto', 'sqrt', 'log2'],
        'bootstrap': [True, False]
    }

    rf = RandomForestRegressor(random_state=42)

    tscv = TimeSeriesSplit(n_splits=5)
    random_search = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_distributions,
        n_iter=30,
        cv=tscv,
        n_jobs=-1,
        verbose=2,
        random_state=42,
        scoring='neg_mean_absolute_error'
    )
    random_search.fit(X_train, y_train)

    return random_search.best_estimator_

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸ Linear Regression
def train_linear_regression_model(X_train, y_train):
    model = LinearRegression()
    model.fit(X_train, y_train)
    return model

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢
def generate_missing_dates(data):
    if data['datetime'].isnull().all():
        st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸§à¸±à¸™à¸—à¸µà¹ˆà¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸²")
        st.stop()
    full_date_range = pd.date_range(start=data['datetime'].min(), end=data['datetime'].max(), freq='15T')
    all_dates = pd.DataFrame(full_date_range, columns=['datetime'])
    data_with_all_dates = pd.merge(all_dates, data, on='datetime', how='left')
    return data_with_all_dates

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¹ƒà¸™à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'code'
def fill_code_column(data):
    if 'code' in data.columns:
        data['code'] = data['code'].fillna(method='ffill').fillna(method='bfill')
    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸«à¸²à¸ˆà¸³à¸™à¸§à¸™à¸—à¸¨à¸™à¸´à¸¢à¸¡
def get_decimal_places(series):
    """
    à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸¡à¸²à¸“à¸ˆà¸³à¸™à¸§à¸™à¸—à¸¨à¸™à¸´à¸¢à¸¡à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢
    """
    # à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ NaN à¹€à¸›à¹‡à¸™à¸ªà¸•à¸£à¸´à¸‡
    series_non_null = series.dropna().astype(str)
    # à¹à¸¢à¸à¸ˆà¸³à¸™à¸§à¸™à¸—à¸¨à¸™à¸´à¸¢à¸¡
    decimal_counts = series_non_null.apply(lambda x: len(x.split('.')[-1]) if '.' in x else 0)
    # à¸„à¸·à¸™à¸„à¹ˆà¸²à¸ˆà¸³à¸™à¸§à¸™à¸—à¸¨à¸™à¸´à¸¢à¸¡à¸—à¸µà¹ˆà¸à¸šà¸šà¹ˆà¸­à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”
    if not decimal_counts.empty:
        return decimal_counts.mode()[0]
    else:
        return 2  # à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸à¸²à¸£à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¸Šà¹ˆà¸§à¸‡à¹à¸£à¸
def handle_initial_missing_values(data, initial_days=2, freq='15T'):
    initial_periods = initial_days * 24 * (60 // 15)  # à¸ˆà¸³à¸™à¸§à¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¹ƒà¸™ initial_days
    for i in range(initial_periods):
        if pd.isna(data['wl_up'].iloc[i]):
            if i == 0:
                # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸”à¹‰à¸§à¸¢à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸ˆà¸¸à¸”à¹à¸£à¸
                data.at[i, 'wl_up'] = data['wl_up'].mean()
            else:
                # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸”à¹‰à¸§à¸¢à¸à¸²à¸£ Interpolation à¹€à¸Šà¸´à¸‡à¹€à¸ªà¹‰à¸™
                data.at[i, 'wl_up'] = data['wl_up'].iloc[i-1]
    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸à¸²à¸£à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹€à¸›à¹‡à¸™à¸£à¸²à¸¢à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œ
def handle_missing_values_by_week(data_clean, start_date, end_date, model_type='random_forest'):
    feature_cols = [
        'wl_up_prev',
        'lag_1', 'lag_4', 'lag_96', 'lag_192',
        'lead_1', 'lead_4', 'lead_96', 'lead_192',
        'ma_672'
    ]

    # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™
    initial_periods = 2 * 24 * (60 // 15)  # initial_days=2
    initial_indices = data_clean.index[:initial_periods]
    filled_initial = data_clean.loc[initial_indices, 'wl_up'].isna()

    data_clean = handle_initial_missing_values(data_clean, initial_days=2)

    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² wl_forecast à¹à¸¥à¸° timestamp à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸•à¸´à¸¡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™
    data_clean.loc[initial_indices[filled_initial], 'wl_forecast'] = data_clean.loc[initial_indices[filled_initial], 'wl_up']
    data_clean.loc[initial_indices[filled_initial], 'timestamp'] = pd.Timestamp.now()

    data = data_clean.copy()

    # Convert start_date and end_date to datetime
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)

    # Filter data based on the datetime range
    data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if data.empty:
        st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        st.stop()

    # Generate all missing dates within the selected range
    data_with_all_dates = generate_missing_dates(data)
    # data_with_all_dates.index = pd.to_datetime(data_with_all_dates['datetime'])  # à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸•à¸±à¹‰à¸‡ index à¹€à¸›à¹‡à¸™ datetime

    # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸² missing à¹ƒà¸™ wl_up_prev
    if 'wl_up_prev' in data_with_all_dates.columns:
        data_with_all_dates['wl_up_prev'] = data_with_all_dates['wl_up_prev'].interpolate(method='linear')
    else:
        data_with_all_dates['wl_up_prev'] = data_with_all_dates['wl_up'].shift(1).interpolate(method='linear')

    # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¹€à¸„à¸¥à¸·à¹ˆà¸­à¸™à¸—à¸µà¹ˆ
    data_with_all_dates = create_lag_lead_features(data_with_all_dates, lags=[1, 4, 96, 192], leads=[1, 4, 96, 192])
    data_with_all_dates = create_moving_average_features(data_with_all_dates, window=672)

    # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸² missing à¹ƒà¸™à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag à¹à¸¥à¸° lead
    lag_cols = ['lag_1', 'lag_4', 'lag_96', 'lag_192']
    lead_cols = ['lead_1', 'lead_4', 'lead_96', 'lead_192']
    ma_col = 'ma_672'
    data_with_all_dates[lag_cols + lead_cols] = data_with_all_dates[lag_cols + lead_cols].interpolate(method='linear')
    data_with_all_dates[ma_col] = data_with_all_dates[ma_col].interpolate(method='linear')

    # à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹à¸¥à¸°à¹„à¸¡à¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›
    data_missing = data_with_all_dates[data_with_all_dates['wl_up'].isna()]
    data_not_missing = data_with_all_dates.dropna(subset=['wl_up'])

    if len(data_missing) == 0:
        st.write("à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ")
        return data_with_all_dates

    # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
    data_filled = data_with_all_dates.copy()

    # à¸„à¹‰à¸™à¸«à¸²à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›
    data_filled['missing_group'] = (data_filled['wl_up'].notnull() != data_filled['wl_up'].notnull().shift()).cumsum()
    missing_groups = data_filled[data_filled['wl_up'].isna()].groupby('missing_group')

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¹‚à¸¡à¹€à¸”à¸¥
    X_train, y_train = prepare_features(data_not_missing)

    # à¸«à¸² number of decimal places
    decimal_places = get_decimal_places(data_clean['wl_up'])

    # **à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²à¹à¸¥à¸°à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸–à¸±à¸”à¹„à¸›** à¸–à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹„à¸¡à¹ˆà¹€à¸à¸µà¸¢à¸‡à¸à¸­
    if len(data_not_missing) < 192:
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²
        week_prev = data_clean[
            (data_clean['datetime'] < start_date) & 
            (data_clean['datetime'] >= start_date - pd.Timedelta(weeks=1))
        ]
        
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸–à¸±à¸”à¹„à¸›
        week_next = data_clean[
            (data_clean['datetime'] > end_date) & 
            (data_clean['datetime'] <= end_date + pd.Timedelta(weeks=1))
        ]

        # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²à¹à¸¥à¸°à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸–à¸±à¸”à¹„à¸›
        data_not_missing = pd.concat([data_not_missing, week_prev, week_next])
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¹ƒà¸«à¸¡à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥
        X_train, y_train = prepare_features(data_not_missing)

    model = train_and_evaluate_model(X_train, y_train, model_type=model_type)

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸–à¸¹à¸à¸à¸¶à¸à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if model is None:
        st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸”à¹‰ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        return data_with_all_dates

    for group_name, group_data in missing_groups:
        missing_length = len(group_data)
        idx_start = group_data.index[0]
        idx_end = group_data.index[-1]

        if missing_length <= 3:
            # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸”à¹‰à¸§à¸¢ interpolation à¸–à¹‰à¸²à¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3 à¹à¸–à¸§
            data_filled.loc[idx_start:idx_end, 'wl_up'] = np.nan  # à¸¢à¸·à¸™à¸¢à¸±à¸™à¸§à¹ˆà¸²à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›à¹€à¸›à¹‡à¸™ NaN
            data_filled['wl_up'] = data_filled['wl_up'].interpolate(method='linear')
            # à¸›à¸±à¸”à¹€à¸¨à¸©à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸•à¸´à¸¡
            data_filled.loc[idx_start:idx_end, 'wl_up'] = data_filled.loc[idx_start:idx_end, 'wl_up'].round(decimal_places)
            # à¸­à¸±à¸›à¹€à¸”à¸•à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ wl_forecast à¹à¸¥à¸° timestamp
            data_filled.loc[idx_start:idx_end, 'wl_forecast'] = data_filled.loc[idx_start:idx_end, 'wl_up']
            data_filled.loc[idx_start:idx_end, 'timestamp'] = pd.Timestamp.now()
        else:
            # à¹ƒà¸Šà¹‰ Linear Regression à¹ƒà¸™à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›
            for idx in group_data.index:
                try:
                    X_missing = data_filled.loc[idx, feature_cols].values.reshape(1, -1)
                    predicted_value = model.predict(X_missing)[0]
                    # à¸›à¸±à¸”à¹€à¸¨à¸©à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ
                    predicted_value = round(predicted_value, decimal_places)
                    # à¸šà¸±à¸™à¸—à¸¶à¸à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸•à¸´à¸¡à¹ƒà¸™à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ wl_up à¹à¸¥à¸° wl_forecast
                    data_filled.at[idx, 'wl_forecast'] = predicted_value
                    data_filled.at[idx, 'wl_up'] = predicted_value
                    data_filled.at[idx, 'timestamp'] = pd.Timestamp.now()
                except Exception as e:
                    st.warning(f"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¹ˆà¸²à¹ƒà¸™à¹à¸–à¸§ {idx} à¹„à¸”à¹‰: {e}")
                    continue

    # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ wl_up2 à¸—à¸µà¹ˆà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡à¸à¸±à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸•à¸´à¸¡
    data_filled['wl_up2'] = data_filled['wl_up']

    # à¸¥à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
    data_filled.drop(columns=['missing_group'], inplace=True)

    data_filled.reset_index(drop=True, inplace=True)
    return data_filled

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆ
def delete_data_by_date_range(data, delete_start_date, delete_end_date):
    # Convert delete_start_date and delete_end_date to datetime
    delete_start_date = pd.to_datetime(delete_start_date)
    delete_end_date = pd.to_datetime(delete_end_date)

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸‚à¸­à¸‡ data à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    data_to_delete = data[(data['datetime'] >= delete_start_date) & (data['datetime'] <= delete_end_date)]

    # à¹€à¸à¸´à¹ˆà¸¡à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸–à¹‰à¸²à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸–à¸¹à¸à¸¥à¸šà¸¡à¸µà¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›
    if len(data_to_delete) == 0:
        st.warning(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ {delete_start_date} à¹à¸¥à¸° {delete_end_date}.")
    elif len(data_to_delete) > (0.3 * len(data)):  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸–à¹‰à¸²à¸¥à¸šà¹€à¸à¸´à¸™ 30% à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        st.warning("à¸„à¸³à¹€à¸•à¸·à¸­à¸™: à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›à¸—à¸µà¹ˆà¸ˆà¸°à¸¥à¸š à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¸¥à¸šà¸–à¸¹à¸à¸¢à¸à¹€à¸¥à¸´à¸")
    else:
        # à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² wl_up à¹€à¸›à¹‡à¸™ NaN
        data.loc[data_to_delete.index, 'wl_up'] = np.nan

    return data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
def calculate_accuracy_metrics(original, filled, data_deleted):
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡ DataFrame à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime' à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if 'datetime' not in original.columns or 'datetime' not in filled.columns:
        st.error("à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™ DataFrame à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime'")
        return

    # à¸œà¸ªà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡ datetime
    merged_data = pd.merge(original[['datetime', 'wl_up']], filled[['datetime', 'wl_up2']], on='datetime')

    # à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸à¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸–à¸¹à¸à¸¥à¸š
    deleted_datetimes = data_deleted[data_deleted['wl_up'].isna()]['datetime']
    merged_data = merged_data[merged_data['datetime'].isin(deleted_datetimes)]

    # à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ NaN à¸­à¸­à¸
    merged_data = merged_data.dropna(subset=['wl_up', 'wl_up2'])

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¸¢à¸‡à¸à¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if merged_data.empty:
        st.info("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸¥à¸šà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³")
        return

    # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
    mse = mean_squared_error(merged_data['wl_up'], merged_data['wl_up2'])
    mae = mean_absolute_error(merged_data['wl_up'], merged_data['wl_up2'])
    r2 = r2_score(merged_data['wl_up'], merged_data['wl_up2'])

    st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", divider='gray')

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="Mean Squared Error (MSE)", value=f"{mse:.4f}")
    with col2:
        st.metric(label="Mean Absolute Error (MAE)", value=f"{mae:.4f}")
    with col3:
        st.metric(label="R-squared (RÂ²)", value=f"{r2:.4f}")

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression
def calculate_accuracy_metrics_linear(original, filled):
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡ DataFrame à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime' à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if 'datetime' not in original.columns or 'datetime' not in filled.columns:
        st.error("à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™ DataFrame à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime'")
        return None, None, None, pd.DataFrame()

    # à¸œà¸ªà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡ datetime
    merged_data = pd.merge(original[['datetime', 'wl_up']], filled[['datetime', 'wl_up2']], on='datetime')

    # à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ NaN à¸­à¸­à¸
    merged_data = merged_data.dropna(subset=['wl_up', 'wl_up2'])

    if merged_data.empty:
        st.info("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸² MAE à¹à¸¥à¸° RMSE à¹„à¸”à¹‰")
        return None, None, None, merged_data

    # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
    mse = mean_squared_error(merged_data['wl_up'], merged_data['wl_up2'])
    mae = mean_absolute_error(merged_data['wl_up'], merged_data['wl_up2'])
    r2 = r2_score(merged_data['wl_up'], merged_data['wl_up2'])

    return mse, mae, r2, merged_data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š
def create_comparison_table_streamlit(forecasted_data, actual_data):
    comparison_df = pd.DataFrame({
        'Datetime': actual_data['datetime'],
        'à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡': actual_data['wl_up'],
        'à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ': forecasted_data['wl_up2']
    })
    return comparison_df

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ (Random Forest)
def plot_results(data_before, data_filled, data_deleted, data_deleted_option=False):
    data_before_filled = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_before['datetime'],
        'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡': data_before['wl_up']
    })

    data_after_filled = pd.DataFrame({
        'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_filled['datetime'],
        'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²': data_filled['wl_up2']
    })

    if data_deleted_option and data_deleted is not None:
        data_after_deleted = pd.DataFrame({
            'à¸§à¸±à¸™à¸—à¸µà¹ˆ': data_deleted['datetime'],
            'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š': data_deleted['wl_up']
        })
    else:
        data_after_deleted = None

    # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸²à¸Ÿ
    combined_data = pd.merge(data_before_filled, data_after_filled, on='à¸§à¸±à¸™à¸—à¸µà¹ˆ', how='outer')

    if data_after_deleted is not None and not data_after_deleted.empty:
        combined_data = pd.merge(combined_data, data_after_deleted, on='à¸§à¸±à¸™à¸—à¸µà¹ˆ', how='outer')

    # à¸à¸³à¸«à¸™à¸”à¸¥à¸³à¸”à¸±à¸šà¸‚à¸­à¸‡ y_columns à¹à¸¥à¸°à¸£à¸°à¸šà¸¸à¸ªà¸µà¸•à¸²à¸¡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚
    if data_after_deleted is not None and not data_after_deleted.empty:
        # à¸–à¹‰à¸²à¸¡à¸µ "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š"
        y_columns = ["à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡", "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²","à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š"]
        # à¸£à¸°à¸šà¸¸à¸ªà¸µà¹€à¸‰à¸à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¹€à¸ªà¹‰à¸™
        color_discrete_map = {
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š": "#00cc96",
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²": "#636efa",
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡": "#ef553b"
        }
    else:
        # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸¥à¸š"
        y_columns = ["à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²", "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡"]
        # à¸£à¸°à¸šà¸¸à¸ªà¸µà¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸ªà¹‰à¸™
        color_discrete_map = {
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡": "#ef553b",
            "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²": "#636efa"
        }

    # à¸§à¸²à¸”à¸à¸£à¸²à¸Ÿà¸”à¹‰à¸§à¸¢ Plotly à¹‚à¸”à¸¢à¸£à¸°à¸šà¸¸à¸ªà¸µà¸‚à¸­à¸‡à¹€à¸ªà¹‰à¸™
    fig = px.line(combined_data, x='à¸§à¸±à¸™à¸—à¸µà¹ˆ', y=y_columns,
                  labels={'value': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)', 'variable': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥'},
                  color_discrete_map=color_discrete_map)

    fig.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)")

    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ
    st.header("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›", divider='gray')
    st.plotly_chart(fig, use_container_width=True)

    # à¹à¸ªà¸”à¸‡à¸•à¸²à¸£à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²
    st.header("à¸•à¸²à¸£à¸²à¸‡à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²", divider='gray')
    data_filled_selected = data_filled[['code', 'datetime', 'wl_up2', 'wl_forecast', 'timestamp']]
    st.dataframe(data_filled_selected, use_container_width=True)

    # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸–à¹‰à¸²à¸¡à¸µà¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    if data_deleted_option:
        calculate_accuracy_metrics(data_before, data_filled, data_deleted)
    else:
        st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³", divider='gray')
        st.info("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ (à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression)
def plot_data_combined_LR_stations(data, forecasted=None, upstream_data=None, downstream_data=None, label='à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³'):
    # à¸à¸£à¸²à¸Ÿà¹à¸£à¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡
    fig_actual = px.line(data, x='datetime', y='wl_up', title=f'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µ {label}', labels={'x': 'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'wl_up': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'})
    fig_actual.update_traces(connectgaps=False, name='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ')
    
    # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Upstream (à¸–à¹‰à¸²à¸¡à¸µ)
    if upstream_data is not None:
        fig_actual.add_scatter(x=upstream_data['datetime'], y=upstream_data['wl_up'], mode='lines', name='à¸ªà¸–à¸²à¸™à¸µ Upstream', line=dict(color='green'))
    
    # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Downstream (à¸–à¹‰à¸²à¸¡à¸µ)
    if downstream_data is not None:
        fig_actual.add_scatter(x=downstream_data['datetime'], y=downstream_data['wl_up'], mode='lines', name='à¸ªà¸–à¸²à¸™à¸µ Downstream', line=dict(color='purple'))

    fig_actual.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)", legend_title="à¸ªà¸–à¸²à¸™à¸µ")

    # à¸à¸£à¸²à¸Ÿà¸—à¸µà¹ˆà¸ªà¸­à¸‡: à¸„à¹ˆà¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    if forecasted is not None and not forecasted.empty:
        # à¸à¸³à¸«à¸™à¸”à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        forecast_start = forecasted['datetime'].min()
        forecast_end = forecasted['datetime'].max()
        actual_forecast_period = data[(data['datetime'] >= forecast_start) & (data['datetime'] <= forecast_end)]
        
        fig_forecast = px.line(forecasted, x='datetime', y='wl_up', title='à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ', labels={'x': 'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'wl_up': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'})
        fig_forecast.update_traces(connectgaps=False, name='à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ', line=dict(color='red'))
        
        # à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        if not actual_forecast_period.empty:
            fig_forecast.add_scatter(x=actual_forecast_period['datetime'], y=actual_forecast_period['wl_up'], mode='lines', name='à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡', line=dict(color='blue'))
        
        fig_forecast.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)", legend_title="à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
    else:
        fig_forecast = None

    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ
    st.plotly_chart(fig_actual, use_container_width=True)
    if fig_forecast is not None:
        st.plotly_chart(fig_forecast, use_container_width=True)

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
def merge_data(df1, df2=None, df3=None):
    if df2 is not None:
        merged_df = pd.merge(df1, df2[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_upstream'))
    else:
        merged_df = df1.copy()
    
    if df3 is not None:
        merged_df = pd.merge(merged_df, df3[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_downstream'))
    return merged_df

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression)
def merge_data_linear(df1, df2=None, suffix='_prev'):
    if df2 is not None:
        merged_df = pd.merge(df1, df2[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', suffix))
    else:
        # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ df2 à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'wl_up_prev' à¸ˆà¸²à¸ 'wl_up' à¸‚à¸­à¸‡ df1 (shifted by 1)
        df1['wl_up_prev'] = df1['wl_up'].shift(1)
        merged_df = df1.copy()
    return merged_df

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ Linear Regression à¸ªà¸³à¸«à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸ªà¸–à¸²à¸™à¸µ
def forecast_with_linear_regression_multi_corrected(data, forecast_start_date, forecast_days, upstream_data=None, downstream_data=None, delay_hours_up=0, delay_hours_down=0):
    if forecast_days < 1 or forecast_days > 30:
        st.error("à¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆ 1 à¸–à¸¶à¸‡ 30 à¸§à¸±à¸™")
        return pd.DataFrame()

    lags = [1, 4, 96, 192]  # lag 15 à¸™à¸²à¸—à¸µ, 1 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡, 1 à¸§à¸±à¸™, 2 à¸§à¸±à¸™

    feature_cols = [f'lag_{lag}' for lag in lags] + \
                   [f'lag_{lag}_upstream' for lag in lags] + \
                   [f'lag_{lag}_downstream' for lag in lags]

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ upstream_data à¸–à¹‰à¸²à¸¡à¸µ
    if upstream_data is not None and not upstream_data.empty:
        upstream_data = upstream_data.copy()
        if delay_hours_up > 0:
            upstream_data['datetime'] = upstream_data['datetime'] + pd.Timedelta(hours=delay_hours_up)
    else:
        # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¹€à¸›à¸¥à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸š upstream
        upstream_data = pd.DataFrame({'datetime': data['datetime'], 'wl_up': [0]*len(data)}, columns=['datetime', 'wl_up'])

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ downstream_data à¸–à¹‰à¸²à¸¡à¸µ
    if downstream_data is not None and not downstream_data.empty:
        downstream_data = downstream_data.copy()
        if delay_hours_down > 0:
            downstream_data['datetime'] = downstream_data['datetime'] + pd.Timedelta(hours=delay_hours_down)
    else:
        # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¹€à¸›à¸¥à¹ˆà¸²à¸ªà¸³à¸«à¸£à¸±à¸š downstream
        downstream_data = pd.DataFrame({'datetime': data['datetime'], 'wl_up': [0]*len(data)}, columns=['datetime', 'wl_up'])

    # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ upstream à¹à¸¥à¸° downstream
    training_data = data.copy()
    training_data = pd.merge(training_data, upstream_data[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_upstream'))
    training_data = pd.merge(training_data, downstream_data[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_downstream'))

    # à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œ lag
    for lag in lags:
        training_data[f'lag_{lag}'] = training_data['wl_up'].shift(lag)
        training_data[f'lag_{lag}_upstream'] = training_data['wl_up_upstream'].shift(lag)
        training_data[f'lag_{lag}_downstream'] = training_data['wl_up_downstream'].shift(lag)

    # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸² NaN à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¹à¸šà¸š forward fill à¹à¸¥à¹‰à¸§à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸¡à¸µ NaN
    training_data.fillna(method='ffill', inplace=True)
    training_data.dropna(inplace=True)

    # à¸à¸³à¸«à¸™à¸”à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¹à¸¥à¸°à¸•à¸±à¸§à¹à¸›à¸£à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
    X_train = training_data[feature_cols]
    y_train = training_data['wl_up']

    # à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥ Linear Regression
    model = LinearRegression()
    model.fit(X_train, y_train)

    # à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    forecast_periods = forecast_days * 96  # à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸•à¸²à¸¡à¸ˆà¸³à¸™à¸§à¸™à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ (96 à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸² 15 à¸™à¸²à¸—à¸µà¸•à¹ˆà¸­à¸§à¸±à¸™)
    forecast_index = pd.date_range(start=forecast_start_date, periods=forecast_periods, freq='15T')
    forecasted_data = pd.DataFrame(index=forecast_index, columns=['wl_up'])

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    combined_data = data.copy()
    combined_data = pd.merge(combined_data, upstream_data[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_upstream'))
    combined_data = pd.merge(combined_data, downstream_data[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', '_downstream'))

    # à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸—à¸µà¸¥à¸°à¸„à¹ˆà¸²
    for idx in forecasted_data.index:
        lag_features = {}
        for lag in lags:
            lag_time = idx - pd.Timedelta(minutes=15 * lag)
            # à¸„à¹ˆà¸² lag à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µà¸«à¸¥à¸±à¸
            if lag_time in combined_data['datetime'].values:
                lag_value = combined_data.loc[combined_data['datetime'] == lag_time, 'wl_up'].values
                if len(lag_value) > 0 and not np.isnan(lag_value[0]):
                    lag_features[f'lag_{lag}'] = lag_value[0]
                else:
                    lag_features[f'lag_{lag}'] = y_train.mean()
            else:
                lag_features[f'lag_{lag}'] = y_train.mean()
            
            # à¸„à¹ˆà¸² lag à¸‚à¸­à¸‡ upstream
            if lag_time in combined_data['datetime'].values:
                lag_up_value = combined_data.loc[combined_data['datetime'] == lag_time, 'wl_up_upstream'].values
                if len(lag_up_value) > 0 and not np.isnan(lag_up_value[0]):
                    lag_features[f'lag_{lag}_upstream'] = lag_up_value[0]
                else:
                    lag_features[f'lag_{lag}_upstream'] = y_train.mean()
            else:
                lag_features[f'lag_{lag}_upstream'] = y_train.mean()
            
            # à¸„à¹ˆà¸² lag à¸‚à¸­à¸‡ downstream
            if lag_time in combined_data['datetime'].values:
                lag_down_value = combined_data.loc[combined_data['datetime'] == lag_time, 'wl_up_downstream'].values
                if len(lag_down_value) > 0 and not np.isnan(lag_down_value[0]):
                    lag_features[f'lag_{lag}_downstream'] = lag_down_value[0]
                else:
                    lag_features[f'lag_{lag}_downstream'] = y_train.mean()
            else:
                lag_features[f'lag_{lag}_downstream'] = y_train.mean()

        # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        X_pred = pd.DataFrame([lag_features], columns=feature_cols)

        try:
            # à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¹ˆà¸²
            forecast_value = model.predict(X_pred)[0]

            # à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸à¸²à¸£à¸à¸£à¸°à¹‚à¸”à¸”à¸‚à¸­à¸‡à¸„à¹ˆà¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
            forecast_value = np.clip(forecast_value, combined_data['wl_up'].min(), combined_data['wl_up'].max())
            
            forecasted_data.at[idx, 'wl_up'] = forecast_value

            # à¸­à¸±à¸›à¹€à¸”à¸• 'combined_data' à¸”à¹‰à¸§à¸¢à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¸£à¸±à¹‰à¸‡à¸–à¸±à¸”à¹„à¸›
            new_row = {'datetime': idx, 'wl_up': forecast_value, 'wl_up_upstream': 0, 'wl_up_downstream': 0}  # à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ upstream/downstream à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹ƒà¸«à¸¡à¹ˆ à¸ªà¸²à¸¡à¸²à¸£à¸–à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸›à¹‡à¸™ 0 à¸«à¸£à¸·à¸­à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
            combined_data = combined_data.append(new_row, ignore_index=True)
        except Exception as e:
            st.warning(f"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸„à¹ˆà¸²à¹ƒà¸™à¹€à¸§à¸¥à¸² {idx} à¹„à¸”à¹‰: {e}")

    # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime' à¸ˆà¸²à¸ index
    forecasted_data['datetime'] = forecasted_data.index

    return forecasted_data

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸–à¸²à¸™à¸µà¸•à¹ˆà¸²à¸‡à¹†
def plot_data_preview(df_pre, df2_pre, df3_pre, total_time_lag_upstream, total_time_lag_downstream):
    data_pre1 = pd.DataFrame({
        'datetime': df_pre['datetime'],
        'à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢': df_pre['wl_up']
    })

    combined_data_pre = data_pre1.copy()

    if df2_pre is not None:
        data_pre2 = pd.DataFrame({
            'datetime': df2_pre['datetime'] + total_time_lag_upstream,  # à¸‚à¸¢à¸±à¸šà¸§à¸±à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Upstream à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸
            'à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Upstream': df2_pre['wl_up']
        })
        combined_data_pre = pd.merge(combined_data_pre, data_pre2, on='datetime', how='outer')

    if df3_pre is not None:
        data_pre3 = pd.DataFrame({
            'datetime': df3_pre['datetime'] - total_time_lag_downstream,  # à¸‚à¸¢à¸±à¸šà¸§à¸±à¸™à¸—à¸µà¹ˆà¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Downstream à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸
            'à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Downstream': df3_pre['wl_up']
        })
        combined_data_pre = pd.merge(combined_data_pre, data_pre3, on='datetime', how='outer')

    # à¸à¸³à¸«à¸™à¸”à¸£à¸²à¸¢à¸à¸²à¸£ y à¸—à¸µà¹ˆà¸ˆà¸°à¹à¸ªà¸”à¸‡à¹ƒà¸™à¸à¸£à¸²à¸Ÿ
    y_columns = ['à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢']
    if df2_pre is not None:
        y_columns.append('à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Upstream')
    if df3_pre is not None:
        y_columns.append('à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Downstream')

    # Plot à¸”à¹‰à¸§à¸¢ Plotly
    fig = px.line(
        combined_data_pre, 
        x='datetime', 
        y=y_columns,
        labels={'value': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)', 'variable': 'à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥'},
        title='à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸–à¸²à¸™à¸µà¸•à¹ˆà¸²à¸‡à¹†',
        color_discrete_sequence=px.colors.qualitative.Plotly
    )

    fig.update_layout(
        xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", 
        yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)"
    )

    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ
    st.plotly_chart(fig, use_container_width=True)

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ (à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression)
def plot_data_combined_LR_stations(data, forecasted=None, upstream_data=None, downstream_data=None, label='à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³'):
    # à¸à¸£à¸²à¸Ÿà¹à¸£à¸: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡
    fig_actual = px.line(data, x='datetime', y='wl_up', title=f'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¸ªà¸–à¸²à¸™à¸µ {label}', labels={'x': 'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'wl_up': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'})
    fig_actual.update_traces(connectgaps=False, name='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ')
    
    # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Upstream (à¸–à¹‰à¸²à¸¡à¸µ)
    if upstream_data is not None:
        fig_actual.add_scatter(x=upstream_data['datetime'], y=upstream_data['wl_up'], mode='lines', name='à¸ªà¸–à¸²à¸™à¸µ Upstream', line=dict(color='green'))
    
    # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Downstream (à¸–à¹‰à¸²à¸¡à¸µ)
    if downstream_data is not None:
        fig_actual.add_scatter(x=downstream_data['datetime'], y=downstream_data['wl_up'], mode='lines', name='à¸ªà¸–à¸²à¸™à¸µ Downstream', line=dict(color='purple'))

    fig_actual.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)", legend_title="à¸ªà¸–à¸²à¸™à¸µ")

    # à¸à¸£à¸²à¸Ÿà¸—à¸µà¹ˆà¸ªà¸­à¸‡: à¸„à¹ˆà¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
    if forecasted is not None and not forecasted.empty:
        # à¸à¸³à¸«à¸™à¸”à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        forecast_start = forecasted['datetime'].min()
        forecast_end = forecasted['datetime'].max()
        actual_forecast_period = data[(data['datetime'] >= forecast_start) & (data['datetime'] <= forecast_end)]
        
        fig_forecast = px.line(forecasted, x='datetime', y='wl_up', title='à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ', labels={'x': 'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'wl_up': 'à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)'})
        fig_forecast.update_traces(connectgaps=False, name='à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œ', line=dict(color='red'))
        
        # à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        if not actual_forecast_period.empty:
            fig_forecast.add_scatter(x=actual_forecast_period['datetime'], y=actual_forecast_period['wl_up'], mode='lines', name='à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡', line=dict(color='blue'))
        
        fig_forecast.update_layout(xaxis_title="à¸§à¸±à¸™à¸—à¸µà¹ˆ", yaxis_title="à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ (wl_up)", legend_title="à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
    else:
        fig_forecast = None

    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ
    st.plotly_chart(fig_actual, use_container_width=True)
    if fig_forecast is not None:
        st.plotly_chart(fig_forecast, use_container_width=True)

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression Corrected)
def merge_data_linear_corrected(df1, df2=None, df3=None, suffix='_prev'):
    if df2 is not None:
        merged_df = pd.merge(df1, df2[['datetime', 'wl_up']], on='datetime', how='left', suffixes=('', suffix))
    else:
        # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ df2 à¹ƒà¸«à¹‰à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'wl_up_prev' à¸ˆà¸²à¸ 'wl_up' à¸‚à¸­à¸‡ df1 (shifted by 1)
        df1['wl_up_prev'] = df1['wl_up'].shift(1)
        merged_df = df1.copy()
    return merged_df

# Streamlit UI
st.set_page_config(
    page_title="à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³",
    page_icon="ğŸŒŠ",
    layout="wide"
)

st.markdown("""
# à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³

à¹à¸­à¸› Streamlit à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ **Random Forest** à¸«à¸£à¸·à¸­ **Linear Regression** à¹€à¸à¸·à¹ˆà¸­à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›à¹à¸¥à¸°à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥à¸œà¹ˆà¸²à¸™à¸à¸£à¸²à¸Ÿà¹à¸¥à¸°à¸à¸²à¸£à¸§à¸±à¸”à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¸·à¸­à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ, 
à¸à¸³à¸«à¸™à¸”à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰
""")
st.markdown("---")

# Sidebar: Upload files and choose date ranges
with st.sidebar:

    st.sidebar.title("à¹€à¸¥à¸·à¸­à¸à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ")
    model_choice = st.sidebar.radio("", ("Random Forest", "Linear Regression"),
        label_visibility="collapsed"  # à¸‹à¹ˆà¸­à¸™ label visibility
    )

    st.sidebar.title("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
    if model_choice == "Random Forest":
        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Random Forest", expanded=False):
            use_upstream = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µ Upstream", value=False)
            use_downstream = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µ Downstream", value=False)
            
            # à¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ªà¸–à¸²à¸™à¸µà¸«à¸¥à¸±à¸à¹à¸¥à¸°à¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Upstream
            if use_upstream:
                uploaded_up_file = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Upstream", type="csv", key="uploader_up")
                time_lag_upstream = st.number_input("à¸£à¸°à¸šà¸¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ Upstream (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)", value=0, min_value=0)
                total_time_lag_upstream = pd.Timedelta(hours=time_lag_upstream)
            else:
                uploaded_up_file = None
                total_time_lag_upstream = pd.Timedelta(hours=0)
            
            # à¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ªà¸–à¸²à¸™à¸µà¸™à¹‰à¸³ Downstream
            if use_downstream:
                uploaded_down_file = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Downstream", type="csv", key="uploader_down")
                time_lag_downstream = st.number_input("à¸£à¸°à¸šà¸¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ Downstream (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)", value=0, min_value=0)
                total_time_lag_downstream = pd.Timedelta(hours=time_lag_downstream)
            else:
                uploaded_down_file = None
                total_time_lag_downstream = pd.Timedelta(hours=0)

            # à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ªà¸–à¸²à¸™à¸µà¸«à¸¥à¸±à¸
            uploaded_file = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢", type="csv", key="uploader1")

        # à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¹ƒà¸™ sidebar
        with st.sidebar.expander("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", expanded=False):
            start_date = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™", value=pd.to_datetime("2024-08-01"))
            end_date = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”", value=pd.to_datetime("2024-08-31")) + pd.DateOffset(hours=23, minutes=45)
            
            # à¹€à¸à¸´à¹ˆà¸¡à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
            delete_data_option = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=False)

            if delete_data_option:
                # à¹à¸ªà¸”à¸‡à¸Šà¹ˆà¸­à¸‡à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸¡à¸·à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸•à¸´à¹Šà¸à¹€à¸¥à¸·à¸­à¸
                st.header("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
                delete_start_date = st.date_input("à¸à¸³à¸«à¸™à¸”à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=start_date, key='delete_start')
                delete_start_time = st.time_input("à¹€à¸§à¸¥à¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™", value=pd.Timestamp("00:00:00").time(), key='delete_start_time')
                delete_end_date = st.date_input("à¸à¸³à¸«à¸™à¸”à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value=end_date, key='delete_end')
                delete_end_time = st.time_input("à¹€à¸§à¸¥à¸²à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”", value=pd.Timestamp("23:45:00").time(), key='delete_end_time')

        process_button = st.button("à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥", type="primary")

    elif model_choice == "Linear Regression":
        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Linear Regression", expanded=False):
            use_nearby_lr = st.checkbox("à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡", value=False)
            
            # Checkbox à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰ Upstream à¹à¸¥à¸° Downstream
            if use_nearby_lr:
                use_upstream_lr = st.checkbox("à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µ Upstream", value=True)
                use_downstream_lr = st.checkbox("à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸™à¸µ Downstream", value=False)
            else:
                use_upstream_lr = False
                use_downstream_lr = False
            
            # à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
            if use_nearby_lr and use_upstream_lr:
                uploaded_up_lr = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ Upstream", type="csv", key="uploader_up_lr")
            else:
                uploaded_up_lr = None

            if use_nearby_lr and use_downstream_lr:
                uploaded_down_lr = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ Downstream", type="csv", key="uploader_down_lr")
            else:
                uploaded_down_lr = None

            # à¹€à¸à¸´à¹ˆà¸¡à¸Šà¹ˆà¸­à¸‡à¸à¸£à¸­à¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ
            # à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸š delay_hours_up_lr à¹à¸¥à¸° delay_hours_down_lr
            delay_hours_up_lr = 0
            delay_hours_down_lr = 0

            if use_nearby_lr:
                if use_upstream_lr:
                    delay_hours_up_lr = st.number_input("à¸£à¸°à¸šà¸¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ Upstream (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)", value=0, min_value=0)
                    total_time_lag_up_lr = pd.Timedelta(hours=delay_hours_up_lr)
                else:
                    total_time_lag_up_lr = pd.Timedelta(hours=0)

                if use_downstream_lr:
                    delay_hours_down_lr = st.number_input("à¸£à¸°à¸šà¸¸à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¸–à¸²à¸™à¸µ Downstream (à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)", value=0, min_value=0)
                    total_time_lag_down_lr = pd.Timedelta(hours=delay_hours_down_lr)
                else:
                    total_time_lag_down_lr = pd.Timedelta(hours=0)
            else:
                total_time_lag_up_lr = pd.Timedelta(hours=0)
                total_time_lag_down_lr = pd.Timedelta(hours=0)

            # à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸«à¸¥à¸±à¸
            uploaded_fill_lr = st.file_uploader("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", type="csv", key="uploader_fill_lr")
            
        # à¹à¸¢à¸à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
        with st.sidebar.expander("à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", expanded=False):
            training_start_date_lr = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", value=pd.to_datetime("2024-05-01"), key='training_start_lr')
            training_start_time_lr = st.time_input("à¹€à¸§à¸¥à¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", value=pd.Timestamp("00:00:00").time(), key='training_start_time_lr')
            training_end_date_lr = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", value=pd.to_datetime("2024-05-31"), key='training_end_lr')
            training_end_time_lr = st.time_input("à¹€à¸§à¸¥à¸²à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥", value=pd.Timestamp("23:45:00").time(), key='training_end_time_lr')

        with st.sidebar.expander("à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", expanded=False):
            forecast_days_lr = st.number_input("à¸ˆà¸³à¸™à¸§à¸™à¸§à¸±à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ", value=3, min_value=1, step=1)

        process_button_lr = st.button("à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Linear Regression", type="primary")

# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸±à¸™à¸—à¸µà¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
def plot_sample_graph(model_choice, df_pre, df_up_pre, df_down_pre, total_time_lag_upstream, total_time_lag_downstream, df_pre_lr=None, df_up_pre_lr=None, df_down_pre_lr=None, total_time_lag_up_lr=0, total_time_lag_down_lr=0):
    if model_choice == "Random Forest":
        plot_data_preview(df_pre, df_up_pre, df_down_pre, total_time_lag_upstream, total_time_lag_downstream)
    elif model_choice == "Linear Regression" and df_pre_lr is not None:
        plot_data_preview(df_pre_lr, df_up_pre_lr, df_down_pre_lr, total_time_lag_up_lr, total_time_lag_down_lr)

# Main content: Display results after file uploads and date selection
if model_choice == "Random Forest":
    if uploaded_file or uploaded_up_file or uploaded_down_file:  # à¸–à¹‰à¸²à¸¡à¸µà¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸”à¹„à¸Ÿà¸¥à¹Œà¸«à¸™à¸¶à¹ˆà¸‡
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸–à¸¹à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        if uploaded_file is None:
            st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢")
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ Upstream à¸–à¸¹à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰
        if use_upstream and uploaded_up_file is None:
            st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Upstream")
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸²à¸™à¸µ Downstream à¸–à¸¹à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰
        if use_downstream and uploaded_down_file is None:
            st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Downstream")

        # à¸–à¹‰à¸²à¸¡à¸µà¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£
        if uploaded_file and (not use_upstream or uploaded_up_file) and (not use_downstream or uploaded_down_file):
            df = load_data(uploaded_file)

            if df is not None:
                df_pre = clean_data(df)
                df_pre = generate_missing_dates(df_pre)

                # à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰à¹„à¸Ÿà¸¥à¹Œ Upstream
                if use_upstream:
                    if uploaded_up_file is not None:
                        df_up = load_data(uploaded_up_file)
                        if df_up is not None:
                            df_up_pre = clean_data(df_up)
                            df_up_pre = generate_missing_dates(df_up_pre)
                        else:
                            df_up_pre = None
                    else:
                        st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Upstream")
                        df_up_pre = None
                else:
                    df_up_pre = None

                # à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰à¹„à¸Ÿà¸¥à¹Œ Downstream
                if use_downstream:
                    if uploaded_down_file is not None:
                        df_down = load_data(uploaded_down_file)
                        if df_down is not None:
                            df_down_pre = clean_data(df_down)
                            df_down_pre = generate_missing_dates(df_down_pre)
                        else:
                            df_down_pre = None
                    else:
                        st.warning("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸°à¸”à¸±à¸šà¸™à¹‰à¸³ Downstream")
                        df_down_pre = None
                else:
                    df_down_pre = None

                # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸±à¸™à¸—à¸µà¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
                plot_sample_graph(
                    model_choice,
                    df_pre, df_up_pre, df_down_pre,
                    total_time_lag_upstream, total_time_lag_downstream
                )

                if process_button:
                    processing_placeholder = st.empty()
                    processing_placeholder.text("à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥...")

                    df['datetime'] = pd.to_datetime(df['datetime']).dt.tz_localize(None)

                    # à¸›à¸£à¸±à¸šà¸„à¹ˆà¸² end_date à¹€à¸‰à¸à¸²à¸°à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¹à¸¥à¹‰à¸§
                    end_date_dt = pd.to_datetime(end_date) + pd.DateOffset(days=1)

                    # à¸à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸²à¸¡à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸
                    df_filtered = df[(df['datetime'] >= pd.to_datetime(start_date)) & (df['datetime'] <= pd.to_datetime(end_date_dt))]

                    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                    if df_filtered.empty:
                        st.warning("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
                        processing_placeholder.empty()
                        st.stop()

                    # à¸–à¹‰à¸²à¹ƒà¸Šà¹‰ Upstream à¹à¸¥à¸°à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œ Upstream à¹à¸¥à¸° df_up_pre à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ None
                    if use_upstream and uploaded_up_file and df_up_pre is not None:
                        # à¸›à¸£à¸±à¸šà¹€à¸§à¸¥à¸²à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Upstream à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸
                        df_up_pre['datetime'] = pd.to_datetime(df_up_pre['datetime']).dt.tz_localize(None)
                        df_up_filtered = df_up_pre[(df_up_pre['datetime'] >= pd.to_datetime(start_date)) & (df_up_pre['datetime'] <= pd.to_datetime(end_date_dt))]
                        df_up_filtered['datetime'] = df_up_filtered['datetime'] + total_time_lag_upstream
                        df_up_clean = clean_data(df_up_filtered)
                    else:
                        df_up_clean = None

                    # à¸–à¹‰à¸²à¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰à¹„à¸Ÿà¸¥à¹Œ Downstream
                    if use_downstream and uploaded_down_file and df_down_pre is not None:
                        # à¸›à¸£à¸±à¸šà¹€à¸§à¸¥à¸²à¸‚à¸­à¸‡à¸ªà¸–à¸²à¸™à¸µ Downstream à¸•à¸²à¸¡à¹€à¸§à¸¥à¸²à¸«à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸
                        df_down_pre['datetime'] = pd.to_datetime(df_down_pre['datetime']).dt.tz_localize(None)
                        df_down_filtered = df_down_pre[
                            (df_down_pre['datetime'] >= pd.to_datetime(start_date)) & 
                            (df_down_pre['datetime'] <= pd.to_datetime(end_date_dt))
                        ]
                        df_down_filtered['datetime'] = df_down_filtered['datetime'] - total_time_lag_downstream  # **à¸–à¸­à¸¢à¹€à¸§à¸¥à¸²** à¹à¸—à¸™à¸à¸²à¸£à¹€à¸à¸´à¹ˆà¸¡
                        df_down_clean = clean_data(df_down_filtered)
                    else:
                        df_down_clean = None

                    # à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸
                    df_clean = clean_data(df_filtered)

                    # **à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸à¸²à¸£à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¹à¸•à¹ˆà¸à¹ˆà¸­à¸™à¸à¸²à¸£à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥**
                    df_before_deletion = df_clean.copy()

                    # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ªà¸–à¸²à¸™à¸µ Upstream à¹à¸¥à¸° Downstream à¸–à¹‰à¸²à¸¡à¸µ
                    df_merged = merge_data(df_clean, df_up_clean, df_down_clean)

                    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¸ˆà¸°à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                    if delete_data_option:
                        delete_start_datetime = pd.to_datetime(f"{delete_start_date} {delete_start_time}")
                        delete_end_datetime = pd.to_datetime(f"{delete_end_date} {delete_end_time}")
                        df_deleted = delete_data_by_date_range(df_merged, delete_start_datetime, delete_end_datetime)
                    else:
                        df_deleted = df_merged.copy()  # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸¥à¸·à¸­à¸à¸¥à¸šà¸à¹‡à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¸´à¸¡à¹à¸—à¸™

                    # Generate all dates
                    df_clean = generate_missing_dates(df_deleted)

                    # Fill NaN values in 'code' column
                    df_clean = fill_code_column(df_clean)

                    # Create time features
                    df_clean = create_time_features(df_clean)

                    # à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸² missing à¹ƒà¸™ 'wl_up_prev'
                    if 'wl_up_prev' not in df_clean.columns:
                        df_clean['wl_up_prev'] = df_clean['wl_up'].shift(1)
                    df_clean['wl_up_prev'] = df_clean['wl_up_prev'].interpolate(method='linear')

                    # Handle missing values by week
                    df_handled = handle_missing_values_by_week(df_clean, start_date, end_date, model_type='random_forest')

                    # Remove the processing message after the processing is complete
                    processing_placeholder.empty()

                    # Plot the results using Streamlit's line chart
                    plot_results(df_before_deletion, df_handled, df_deleted, data_deleted_option=delete_data_option)

            st.markdown("---")

    else:
        st.info("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸”à¹‰à¸§à¸¢ Random Forest")

elif model_choice == "Linear Regression":
    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸±à¸™à¸—à¸µà¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
    if uploaded_fill_lr:  # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸±à¸™à¸—à¸µà¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
        try:
            target_df_lr = pd.read_csv(uploaded_fill_lr)
        except Exception as e:
            st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ: {e}")
            target_df_lr = pd.DataFrame()

        if target_df_lr.empty:
            st.error("à¹„à¸Ÿà¸¥à¹Œ CSV à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸•à¸´à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸² à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        else:
            target_df_lr = clean_data(target_df_lr)
            if target_df_lr.empty:
                st.error("à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸à¸²à¸£à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸«à¸¥à¸·à¸­")
            else:
                target_df_lr = generate_missing_dates(target_df_lr)
                target_df_lr['datetime'] = pd.to_datetime(target_df_lr['datetime'], errors='coerce').dt.tz_localize(None)
                target_df_lr = create_time_features(target_df_lr)

                # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Upstream à¸–à¹‰à¸²à¸¡à¸µ
                if use_nearby_lr and use_upstream_lr and uploaded_up_lr is not None:
                    try:
                        upstream_df_lr = pd.read_csv(uploaded_up_lr)
                    except Exception as e:
                        st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Upstream: {e}")
                        upstream_df_lr = pd.DataFrame()

                    upstream_df_lr = clean_data(upstream_df_lr)
                    if not upstream_df_lr.empty:
                        upstream_df_lr = generate_missing_dates(upstream_df_lr)
                        upstream_df_lr['datetime'] = pd.to_datetime(upstream_df_lr['datetime'], errors='coerce').dt.tz_localize(None)
                        upstream_df_lr = create_time_features(upstream_df_lr)
                else:
                    upstream_df_lr = None

                # à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Downstream à¸–à¹‰à¸²à¸¡à¸µ
                if use_nearby_lr and use_downstream_lr and uploaded_down_lr is not None:
                    try:
                        downstream_df_lr = pd.read_csv(uploaded_down_lr)
                    except Exception as e:
                        st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Downstream: {e}")
                        downstream_df_lr = pd.DataFrame()

                    downstream_df_lr = clean_data(downstream_df_lr)
                    if not downstream_df_lr.empty:
                        downstream_df_lr = generate_missing_dates(downstream_df_lr)
                        downstream_df_lr['datetime'] = pd.to_datetime(downstream_df_lr['datetime'], errors='coerce').dt.tz_localize(None)
                        downstream_df_lr = create_time_features(downstream_df_lr)
                else:
                    downstream_df_lr = None

                # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ upstream à¹à¸¥à¸° downstream à¸–à¹‰à¸²à¸¡à¸µ
                if use_nearby_lr and (use_upstream_lr or use_downstream_lr):
                    merged_training_data_lr = merge_data_linear_corrected(target_df_lr, upstream_df_lr if use_upstream_lr else None)
                    merged_training_data_lr = merge_data_linear_corrected(merged_training_data_lr, downstream_df_lr if use_downstream_lr else None)
                else:
                    merged_training_data_lr = merge_data_linear_corrected(target_df_lr)

                # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸±à¸™à¸—à¸µà¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ
                st.header("à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ (Linear Regression)", divider='gray')
                plot_sample_graph(
                    model_choice,
                    target_df_lr, upstream_df_lr, downstream_df_lr,
                    total_time_lag_up_lr, total_time_lag_down_lr
                )

    # à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹€à¸¡à¸·à¹ˆà¸­à¸à¸”à¸›à¸¸à¹ˆà¸¡ "à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Linear Regression"
    if process_button_lr:
        if uploaded_fill_lr is None:
            st.error("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ªà¸³à¸«à¸£à¸±à¸š Linear Regression")
        else:
            if 'target_df_lr' not in locals() or target_df_lr.empty:
                st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
            else:
                with st.spinner("à¸à¸³à¸¥à¸±à¸‡à¸à¸¢à¸²à¸à¸£à¸“à¹Œ..."):
                    training_start_datetime_lr = pd.Timestamp.combine(training_start_date_lr, training_start_time_lr)
                    training_end_datetime_lr = pd.Timestamp.combine(training_end_date_lr, training_end_time_lr)
                    training_data_lr = merged_training_data_lr[
                        (merged_training_data_lr['datetime'] >= training_start_datetime_lr) & 
                        (merged_training_data_lr['datetime'] <= training_end_datetime_lr)
                    ].copy()

                    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
                    if training_data_lr.empty:
                        st.error("à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥")
                        st.stop()
                    else:
                        forecast_start_date_actual_lr = training_end_datetime_lr + pd.Timedelta(minutes=15)
                        forecast_end_date_actual_lr = forecast_start_date_actual_lr + pd.Timedelta(days=forecast_days_lr)
                        max_datetime_lr = target_df_lr['datetime'].max()

                        if forecast_end_date_actual_lr > max_datetime_lr:
                            st.warning("à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸¡à¹ˆà¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")

                        forecasted_data_lr = forecast_with_linear_regression_multi_corrected(
                            data=target_df_lr,  # à¸ªà¹ˆà¸‡ DataFrame à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime'
                            upstream_data=upstream_df_lr if upstream_df_lr is not None else None,
                            downstream_data=downstream_df_lr if downstream_df_lr is not None else None,
                            forecast_start_date=forecast_start_date_actual_lr,
                            forecast_days=forecast_days_lr,
                            delay_hours_up=delay_hours_up_lr if use_nearby_lr and use_upstream_lr else 0,
                            delay_hours_down=delay_hours_down_lr if use_nearby_lr and use_downstream_lr else 0
                        )

                        if not forecasted_data_lr.empty:
                            # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸š Random Forest
                            st.header("à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ (Linear Regression)", divider='gray')
                            plot_data_combined_LR_stations(
                                target_df_lr,  # à¸ªà¹ˆà¸‡ DataFrame à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'datetime'
                                forecasted_data_lr, 
                                upstream_df_lr if upstream_df_lr is not None else None, 
                                downstream_df_lr if downstream_df_lr is not None else None, 
                                label='à¸ªà¸–à¸²à¸™à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢'
                            )
                            st.markdown("---")  # à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¹‰à¸™à¹à¸šà¹ˆà¸‡

                            # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
                            filled_lr = forecasted_data_lr.reset_index().rename(columns={'index': 'datetime'})
                            filled_lr['wl_up2'] = filled_lr['wl_up']
                            filled_lr.drop(columns=['wl_up'], inplace=True)

                            mse_lr, mae_lr, r2_lr, merged_data_lr = calculate_accuracy_metrics_linear(
                                original=target_df_lr,
                                filled=filled_lr
                            )

                            if mse_lr is not None:
                                st.header("à¸•à¸²à¸£à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š")
                                comparison_table_lr = create_comparison_table_streamlit(forecasted_data_lr, merged_data_lr)
                                st.dataframe(comparison_table_lr, use_container_width=True)
                                
                                st.header("à¸œà¸¥à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³")
                                st.markdown("---")  # à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¹‰à¸™à¹à¸šà¹ˆà¸‡
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric(label="Mean Squared Error (MSE)", value=f"{mse_lr:.4f}")
                                with col2:
                                    st.metric(label="Mean Absolute Error (MAE)", value=f"{mae_lr:.4f}")
                                with col3:
                                    st.metric(label="R-squared (RÂ²)", value=f"{r2_lr:.4f}")
                            # à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ à¸ˆà¸°à¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸ˆà¸²à¸à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ calculate_accuracy_metrics_linear
                        else:
                            st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸à¸µà¸¢à¸‡à¸à¸­")
    else:
        st.info("à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ CSV à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸”à¹‰à¸§à¸¢ Linear Regression")

























































